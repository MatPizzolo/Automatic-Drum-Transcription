"""
Transcription service — builds sheet music from predicted hits using music21.

Replicates the core logic from AnNOTEator's transcriber.py, adapted for
our hit data format: [{time, instrument, velocity}, ...].
"""

from typing import Any, Dict, List

from app.utils.logging import get_logger

logger = get_logger(__name__)

# Mapping from our canonical instrument names → music21 percussion pitches
INSTRUMENT_PITCH_MAP = {
    "kick": "F4",
    "snare": "C5",
    "hihat_closed": "G5",
    "hihat_open": "G5",
    "ride": "G5",
    "crash": "A5",
    "tom_high": "E5",
    "tom_mid": "D5",
    "tom_low": "A4",
}

# Noteheads that should use 'x' (cymbals)
X_NOTEHEAD_INSTRUMENTS = {"hihat_closed", "hihat_open", "ride", "crash"}


def build_sheet_music(
    hits: List[Dict[str, Any]],
    bpm: int,
    title: str = "Drum Sheet Music",
    beats_per_measure: int = 4,
    note_value: int = 4,
) -> Any:
    """
    Build a music21 Stream from a list of hit dicts.

    Each hit: {"time": float (seconds), "instrument": str, "velocity": float}

    Returns a music21.stream.Stream object.
    """
    from music21 import (
        stream,
        note,
        meter,
        metadata,
        tempo,
        percussion,
        duration,
    )

    logger.info(
        "transcription_start",
        total_hits=len(hits),
        bpm=bpm,
        title=title,
    )

    s = stream.Stream()

    # Metadata
    s.insert(0, meter.TimeSignature(f"{beats_per_measure}/{note_value}"))
    s.insert(0, tempo.MetronomeMark(number=bpm))
    s.insert(0, metadata.Metadata())
    s.metadata.title = title
    s.metadata.composer = "Generated by DrumScribe"

    if not hits:
        s = s.makeMeasures()
        return s

    # Sort hits by time
    hits_sorted = sorted(hits, key=lambda h: h["time"])

    # Group hits by time (simultaneous hits become chords)
    time_groups: Dict[float, List[Dict[str, Any]]] = {}
    for hit in hits_sorted:
        t = round(hit["time"], 4)
        if t not in time_groups:
            time_groups[t] = []
        time_groups[t].append(hit)

    # Calculate beat duration in seconds
    beat_duration_sec = 60.0 / bpm
    eighth_duration_sec = beat_duration_sec / 2

    # Convert time-based hits to music21 offset-based notes
    sorted_times = sorted(time_groups.keys())

    for t in sorted_times:
        group = time_groups[t]

        # Convert time to quarter-note offset from start
        offset_quarters = (t / beat_duration_sec)

        if len(group) == 1:
            hit = group[0]
            instrument = hit["instrument"]
            pitch_str = INSTRUMENT_PITCH_MAP.get(instrument, "C5")

            n = note.Unpitched(pitch_str)
            n.duration = duration.Duration(0.5)  # eighth note default
            if instrument in X_NOTEHEAD_INSTRUMENTS:
                n.notehead = "x"
            n.stemDirection = "up"
            s.insert(offset_quarters, n)
        else:
            # Multiple simultaneous hits → PercussionChord
            notes_group = []
            for hit in group:
                instrument = hit["instrument"]
                pitch_str = INSTRUMENT_PITCH_MAP.get(instrument, "C5")
                _n = note.Unpitched(pitch_str)
                if instrument in X_NOTEHEAD_INSTRUMENTS:
                    _n.notehead = "x"
                notes_group.append(_n)

            chord = percussion.PercussionChord(notes_group)
            chord.duration = duration.Duration(0.5)
            chord.stemDirection = "up"
            s.insert(offset_quarters, chord)

    # Make measures and clean up
    s = s.makeMeasures()

    logger.info(
        "transcription_complete",
        measures=len(s.getElementsByClass("Measure")),
        total_events=len(sorted_times),
    )

    return s
